import runpod
import torch
import os
from qwen_asr import Qwen3ASRModel
from utils import download_audio, split_audio, cleanup_files

# --- é…ç½® ---
# å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ä¸º "Qwen/Qwen3-ASR-1.7B"
MODEL_NAME = "Qwen/Qwen3-ASR-0.6B" 
ALIGNER_NAME = "Qwen/Qwen3-ForcedAligner-0.6B"
# æ¨¡å‹ä¸‹è½½ç›®å½• (ä¸ Dockerfile ä¸­ä¸€è‡´)
MODEL_DIR = "/models/asr"
ALIGNER_DIR = "/models/aligner"

# å…¨å±€å˜é‡ç¼“å­˜æ¨¡å‹
model = None

def init_model():
    global model
    if model is None:
        print("ğŸš€ Loading Qwen3-ASR Model with vLLM backend...")
        try:
            # ä½¿ç”¨ vLLM åç«¯åŠ è½½ï¼Œé€šè¿‡ GPU åŠ é€Ÿ
            model = Qwen3ASRModel.LLM(
                model=MODEL_DIR,
                gpu_memory_utilization=0.7, # æ ¹æ®æ˜¾å¡æ˜¾å­˜è°ƒæ•´ï¼Œ0.7 é€‚åˆ 24GB æ˜¾å¡åŒæ—¶è·‘å…¶ä»–ä»»åŠ¡
                max_new_tokens=4096,
                forced_aligner=ALIGNER_DIR,
                forced_aligner_kwargs={
                    "dtype": torch.bfloat16,
                    "device_map": "cuda:0",
                },
            )
            print("âœ… Model loaded successfully.")
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            raise e

def _clear_kv_cache():
    """æ¸…ç† vLLM çš„ KV cacheï¼Œé˜²æ­¢é•¿éŸ³é¢‘å¤„ç†æ—¶æ˜¾å­˜æ³„æ¼"""
    global model
    if model is not None and hasattr(model, 'llm'):
        try:
            # vLLM 0.3.0+ æ”¯æŒ reset_prefix_cache
            if hasattr(model.llm, 'reset_prefix_cache'):
                model.llm.reset_prefix_cache()
        except Exception as e:
            print(f"âš ï¸ Warning: Failed to clear KV cache: {e}")


def _parse_timestamp_segment(segment, time_offset):
    """
    è§£ææ—¶é—´æˆ³æ®µï¼Œå®‰å…¨å¤„ç†å¤šç§å¯èƒ½çš„è¿”å›æ ¼å¼
    
    Args:
        segment: å¯èƒ½æ˜¯ list [start, end, text] æˆ– dict {"start": x, "end": y, "text": z}
        time_offset: æ—¶é—´åç§»é‡ï¼ˆç§’ï¼‰
        
    Returns:
        dict: {"start": float, "end": float, "text": str}
    """
    try:
        if isinstance(segment, dict):
            # å­—å…¸æ ¼å¼
            start = segment.get("start", segment.get(0, 0))
            end = segment.get("end", segment.get(1, 0))
            text = segment.get("text", segment.get(2, ""))
        elif isinstance(segment, (list, tuple)) and len(segment) >= 2:
            # åˆ—è¡¨æ ¼å¼ [start, end, text?]
            start = segment[0]
            end = segment[1]
            text = segment[2] if len(segment) > 2 else ""
        else:
            # æœªçŸ¥æ ¼å¼ï¼Œå°è¯•è§£æ
            print(f"âš ï¸ Warning: Unknown timestamp segment format: {type(segment)} - {repr(segment)}")
            start = end = 0
            text = str(segment) if segment is not None else ""
        
        # éªŒè¯æ•°å€¼æœ‰æ•ˆæ€§
        start = float(start) if start is not None else 0.0
        end = float(end) if end is not None else 0.0
        
        return {
            "start": start + time_offset,
            "end": end + time_offset,
            "text": str(text) if text is not None else ""
        }
    except Exception as e:
        # ä»»ä½•è§£æé”™è¯¯éƒ½è¿”å›é»˜è®¤å€¼ï¼Œä¸ä¸­æ–­å¤„ç†
        print(f"âš ï¸ Warning: Failed to parse timestamp segment: {e}")
        return {"start": time_offset, "end": time_offset, "text": ""}


def _sanitize_job_id(job_id):
    """æ¸…ç† job IDï¼Œç¡®ä¿é€‚åˆç”¨ä½œæ–‡ä»¶å"""
    import re
    # ç§»é™¤éå­—æ¯æ•°å­—å­—ç¬¦ï¼Œé™åˆ¶é•¿åº¦
    sanitized = re.sub(r'[^a-zA-Z0-9_-]', '_', str(job_id))
    return sanitized[:64]  # é™åˆ¶é•¿åº¦


def handler(job):
    """
    RunPod å¤„ç†å‡½æ•°
    è¾“å…¥æ ¼å¼: {"input": {"audio_url": "https://...", "language": "auto"}}
    """
    job_input = job["input"]
    audio_url = job_input.get("audio_url")
    language = job_input.get("language", None)  # None ä¸ºè‡ªåŠ¨æ£€æµ‹

    if not audio_url:
        return {"error": "Missing 'audio_url' in input."}

    # 1. å‡†å¤‡ç¯å¢ƒ
    safe_job_id = _sanitize_job_id(job.get("id", "unknown"))
    local_audio_path = f"/tmp/{safe_job_id}_raw.mp3"
    chunk_dir = f"/tmp/{safe_job_id}_chunks"
    
    try:
        # 2. ä¸‹è½½éŸ³é¢‘ï¼ˆå¸¦è¶…æ—¶ï¼‰
        print(f"â¬‡ï¸ Downloading audio from {audio_url}...")
        download_audio(audio_url, local_audio_path, timeout=300)

        # 3. ä½¿ç”¨ VAD æ™ºèƒ½åˆ‡åˆ†éŸ³é¢‘
        print("âœ‚ï¸ Splitting audio into chunks using VAD...")
        chunks_info = split_audio_smart(
            local_audio_path, 
            chunk_dir, 
            max_chunk_ms=270000,
            min_silence_ms=300
        )
        print(f"ğŸ“¦ Audio split into {len(chunks_info)} chunks")
        
        full_transcript = []
        full_text = ""
        last_detected_language = None
        
        # 4. é€ä¸ªç‰‡æ®µè½¬å½•
        print(f"ğŸ”„ Processing {len(chunks_info)} chunks...")
        
        for idx, chunk in enumerate(chunks_info):
            chunk_path = chunk["path"]
            time_offset = chunk["start_time_sec"]
            
            print(f"  ğŸ“ Processing chunk {idx + 1}/{len(chunks_info)} ({chunk['start_time_sec']:.1f}s - {chunk['end_time_sec']:.1f}s)...")
            
            # è°ƒç”¨æ¨¡å‹è½¬å½•
            results = model.transcribe(
                audio=chunk_path,
                language=language,
                return_time_stamps=True
            )
            
            res = results[0]
            
            # åˆå¹¶æ–‡æœ¬
            if hasattr(res, 'text'):
                full_text += res.text + " "
            
            # è®°å½•æ£€æµ‹åˆ°çš„è¯­è¨€
            if hasattr(res, 'language'):
                last_detected_language = res.language
            
            # è°ƒæ•´æ—¶é—´æˆ³å¹¶åˆå¹¶
            if hasattr(res, 'time_stamps') and res.time_stamps:
                for segment in res.time_stamps:
                    adjusted_segment = _parse_timestamp_segment(segment, time_offset)
                    full_transcript.append(adjusted_segment)
            
            # æ¯å¤„ç† 3 ä¸ªç‰‡æ®µæ¸…ç†ä¸€æ¬¡ KV cacheï¼Œé˜²æ­¢ OOM
            if (idx + 1) % 3 == 0:
                _clear_kv_cache()

        return {
            "status": "success",
            "text": full_text.strip(),
            "segments": full_transcript,
            "language_detected": last_detected_language
        }

    except Exception as e:
        import traceback
        import os
        
        # æ‰“å°è¯¦ç»†é”™è¯¯æ—¥å¿—åˆ°æœåŠ¡ç«¯
        error_trace = traceback.format_exc()
        print(f"âŒ Error processing job: {e}")
        print(error_trace)
        
        # è¿”å›ç»™å®¢æˆ·ç«¯çš„é”™è¯¯ä¿¡æ¯ï¼ˆéšè—æ•æ„Ÿç»†èŠ‚ï¼‰
        error_type = type(e).__name__
        
        # æ ¹æ®é”™è¯¯ç±»å‹è¿”å›ç”¨æˆ·å‹å¥½çš„æ¶ˆæ¯
        if "Download timeout" in str(e):
            user_message = "Audio download timed out. Please check the URL and try again."
        elif "Failed to download" in str(e):
            user_message = "Failed to download audio from the provided URL."
        elif "CUDA" in str(e) or "cuda" in str(e):
            user_message = "GPU processing error. The service may be temporarily overloaded."
        elif "OutOfMemory" in error_type or "No memory" in str(e):
            user_message = "Audio too long or complex to process. Please try a shorter audio file."
        else:
            # é€šç”¨é”™è¯¯ï¼Œä¸æš´éœ²å†…éƒ¨ç»†èŠ‚
            user_message = f"Processing error ({error_type}). Please try again later."
        
        return {
            "error": user_message,
            "error_type": error_type,
            "job_id": safe_job_id if 'safe_job_id' in locals() else "unknown"
        }
        
    finally:
        # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        cleanup_files([local_audio_path, chunk_dir])

# åˆå§‹åŒ–æ¨¡å‹
init_model()

# å¯åŠ¨ Serverless ç›‘å¬
runpod.serverless.start({"handler": handler})