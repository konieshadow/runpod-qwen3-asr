import runpod
import torch
import os
from qwen_asr import Qwen3ASRModel
from utils import download_audio, split_audio, cleanup_files

# --- é…ç½® ---
# å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ä¸º "Qwen/Qwen3-ASR-1.7B"
MODEL_NAME = "Qwen/Qwen3-ASR-0.6B" 
ALIGNER_NAME = "Qwen/Qwen3-ForcedAligner-0.6B"
# æ¨¡å‹ä¸‹è½½ç›®å½• (ä¸ Dockerfile ä¸­ä¸€è‡´)
MODEL_DIR = "/models/asr"
ALIGNER_DIR = "/models/aligner"

# å…¨å±€å˜é‡ç¼“å­˜æ¨¡å‹
model = None

def init_model():
    global model
    if model is None:
        print("ğŸš€ Loading Qwen3-ASR Model with vLLM backend...")
        try:
            # ä½¿ç”¨ vLLM åç«¯åŠ è½½ï¼Œé€šè¿‡ GPU åŠ é€Ÿ
            model = Qwen3ASRModel.LLM(
                model=MODEL_DIR,
                gpu_memory_utilization=0.7, # æ ¹æ®æ˜¾å¡æ˜¾å­˜è°ƒæ•´ï¼Œ0.7 é€‚åˆ 24GB æ˜¾å¡åŒæ—¶è·‘å…¶ä»–ä»»åŠ¡
                max_new_tokens=4096,
                forced_aligner=ALIGNER_DIR,
                forced_aligner_kwargs={
                    "dtype": torch.bfloat16,
                    "device_map": "cuda:0",
                },
            )
            print("âœ… Model loaded successfully.")
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            raise e

def handler(job):
    """
    RunPod å¤„ç†å‡½æ•°
    è¾“å…¥æ ¼å¼: {"input": {"audio_url": "https://...", "language": "auto"}}
    """
    job_input = job["input"]
    audio_url = job_input.get("audio_url")
    language = job_input.get("language", None) # None ä¸ºè‡ªåŠ¨æ£€æµ‹

    if not audio_url:
        return {"error": "Missing 'audio_url' in input."}

    # 1. å‡†å¤‡ç¯å¢ƒ
    temp_id = job["id"]
    local_audio_path = f"/tmp/{temp_id}_raw.mp3"
    chunk_dir = f"/tmp/{temp_id}_chunks"
    
    try:
        # 2. ä¸‹è½½éŸ³é¢‘
        print(f"â¬‡ï¸ Downloading audio from {audio_url}...")
        download_audio(audio_url, local_audio_path)

        # 3. åˆ‡ç‰‡éŸ³é¢‘ (è§„é¿ ForcedAligner çš„ 5 åˆ†é’Ÿé™åˆ¶)
        # å°†éŸ³é¢‘åˆ‡åˆ†ä¸º 4.5 åˆ†é’Ÿ (270ç§’) çš„ç‰‡æ®µ
        print("âœ‚ï¸ Splitting audio into chunks...")
        chunks_info = split_audio(local_audio_path, chunk_dir, chunk_length_ms=270000)
        
        full_transcript = []
        full_text = ""
        
        # 4. é€ä¸ªç‰‡æ®µè½¬å½•
        # æ³¨æ„ï¼šè¿™é‡Œæ˜¯ä¸²è¡Œå¤„ç†ç‰‡æ®µã€‚å¦‚æœè¿½æ±‚æè‡´é€Ÿåº¦ï¼Œå¯ä»¥ä½¿ç”¨ ThreadPoolExecutor å¹¶è¡Œæäº¤ç»™ vLLM
        # ä½†è€ƒè™‘åˆ°æ—¶é—´æˆ³åˆå¹¶çš„é¡ºåºæ€§ï¼Œä¸²è¡Œæ›´å®¹æ˜“ç»´æŠ¤ã€‚
        print(f"ğŸ”„ Processing {len(chunks_info)} chunks...")
        
        for idx, chunk in enumerate(chunks_info):
            chunk_path = chunk["path"]
            time_offset = chunk["start_time_sec"]
            
            # è°ƒç”¨æ¨¡å‹è½¬å½•
            # Qwen3-ASR çš„ transcribe æ”¯æŒç›´æ¥ä¼ å…¥æ–‡ä»¶è·¯å¾„
            results = model.transcribe(
                audio=chunk_path,
                language=language,
                return_time_stamps=True
            )
            
            res = results[0] # å•æ–‡ä»¶å¤„ç†
            
            # åˆå¹¶æ–‡æœ¬
            full_text += res.text + " "
            
            # è°ƒæ•´æ—¶é—´æˆ³ (åŠ ä¸Šå½“å‰åˆ‡ç‰‡çš„åç§»é‡)
            # ForcedAligner è¿”å›çš„ timestamps ç»“æ„é€šå¸¸æ˜¯List[List[float]] æˆ–è€… List[Dict]
            # Qwen3 è¿”å›çš„æ˜¯å¯¹è±¡ï¼Œæˆ‘ä»¬æå– raw data
            if res.time_stamps:
                for segment in res.time_stamps:
                    # å‡è®¾ segment æ˜¯ [start, end, text] æˆ–ç±»ä¼¼ç»“æ„ï¼Œæ ¹æ®å®é™…è¾“å‡ºè°ƒæ•´
                    # æ‰“å°ä¸€ä¸‹ç»“æ„ä»¥é˜²ä¸‡ä¸€
                    # è°ƒæ•´æ—¶é—´
                    adjusted_segment = {
                        "start": segment[0] + time_offset,
                        "end": segment[1] + time_offset,
                        "text": segment[2] if len(segment) > 2 else ""
                    }
                    full_transcript.append(adjusted_segment)

        return {
            "status": "success",
            "text": full_text.strip(),
            "segments": full_transcript,
            "language_detected": results[0].language # è¿”å›æœ€åä¸€ä¸ªç‰‡æ®µæ£€æµ‹åˆ°çš„è¯­è¨€ä½œä¸ºå‚è€ƒ
        }

    except Exception as e:
        print(f"âŒ Error processing job: {e}")
        return {"error": str(e)}
        
    finally:
        # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        cleanup_files([local_audio_path, chunk_dir])

# åˆå§‹åŒ–æ¨¡å‹
init_model()

# å¯åŠ¨ Serverless ç›‘å¬
runpod.serverless.start({"handler": handler})